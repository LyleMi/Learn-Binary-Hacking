I/O
========================================

I/O模型
----------------------------------------
Linux下主要有以下五种I/O模型

- 阻塞式I/O (blocking IO)
- 非阻塞式I/O (nonblocking I/O)
- I/O 复用 (I/O multiplexing)
- 信号驱动I/O (signal driven I/O (SIGIO))
- 异步I/O (asynchronous I/O)

阻塞I/O 进程会一直阻塞，直到数据拷贝完成。

非阻塞I/O 通过进程反复调用IO函数，在数据拷贝过程中，进程是阻塞的。

I/O 复用主要是select和epoll。一个线程可以对多个IO端口进行监听，当socket有读写事件时分发到具体的线程进行处理。

信号驱动I/O在进程运行时注册一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。

异步I/O相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回，用户态进程继续运行。等到数据准备好后，内核直接复制数据给进程，然后从内核向进程发送通知。在两个IO阶段，进程都是非阻塞的。

IO复用
----------------------------------------
常见的IO复用相关函数有select、poll、epoll。其中epoll是Linux所特有，而select是POSIX所规定，一般操作系统均有实现。

select
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select本质是通过设置或检查存放fd标志位的数据结构来进行下一步处理。缺点是：

- 单个进程可监视的fd数量被限制，限制数目可以通过 ``cat /proc/sys/fs/file-max`` 察看。32位默认是1024个，64位默认为2048个
- 对socket进行扫描时是线性扫描，即采用轮询方法，效率低
- 需要维护一个用来存放大量fd的数据结构，会使得用户空间和内核空间在传递该结构时复制开销大

poll
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
poll本质和select相同，将用户传入的数据拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或主动超时，被唤醒后又要再次遍历fd。

它基于链表来存储数据，因此没有最大连接数的限制，但缺点是：

- 大量的fd的数组不管是否需要，整体在用户态和内核空间之间复制
- poll有“水平触发”的特点，如果报告了fd后，没有被处理，那么下次poll时会再次报告

epoll
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦fd就绪，内核就会采用回调机制来激活该fd，epoll_wait便可以收到通知。

因此epoll有以下优点：

- 没有最大并发连接的限制
- 效率提升，只有活跃可用的FD才会调用回调函数
- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递

io_uring
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
io_uring 引入了一套全新的 syscall 与一套 async API ，相比之前的实现有更高的性能与兼容性。
